# ğŸ“š Web Scraping Project: Book Data Extraction ğŸ“Š
The Web Scraping Project is designed to extract book data from a website and save it to a CSV file. The project uses Python as the primary programming language and leverages libraries such as `requests` and `BeautifulSoup` to fetch and parse HTML pages. The script extracts relevant information such as book titles, prices, and availability, and stores it in a CSV file for further analysis or processing.

## ğŸš€ Key Features
- Extracts book data from a website using web scraping techniques
- Handles exceptions and ensures continuous execution even if errors occur
- Writes scraped data to a CSV file for easy analysis or processing
- Introduces a delay between requests to avoid overwhelming the website
- Uses a User-Agent header to identify the script as a legitimate browser

## ğŸ› ï¸ Tech Stack
- **Frontend:** None
- **Backend:** Python
- **Database:** None
- **Libraries:**
  - `requests`: for sending HTTP requests
  - `BeautifulSoup`: for parsing HTML content
  - `csv`: for writing scraped data to a CSV file
  - `time`: for introducing a delay between requests

## ğŸ“¦ Getting Started / Setup Instructions
### Prerequisites
- Python 3.x installed on your system
- `requests`, `beautifulsoup4`, and `csv` libraries installed

### Installation
To install the required libraries, run the following command:
```bash
pip install requests beautifulsoup4
```
### Running Locally
1. Clone the repository to your local machine
2. Navigate to the project directory
3. Run the script using Python:
```bash
python main.py
```

## ğŸ¤ Contributing
Contributions are welcome! If you'd like to contribute to the project, please fork the repository and submit a pull request with your changes.
